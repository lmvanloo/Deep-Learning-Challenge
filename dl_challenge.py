# -*- coding: utf-8 -*-
"""DL_challenge.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11Dd3nHVuoJBEXk0ZEYJrZ8i0l1nOdEp6

#Dependencies
"""

from google.colab import drive
import numpy as np
import pandas as pd 
import tensorflow as tf
import matplotlib.pyplot as plt
import seaborn as sns
from keras.preprocessing.image import ImageDataGenerator 
from keras.models import Sequential
from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_recall_fscore_support, roc_curve, roc_auc_score

"""#Mounting drive"""

drive.mount('/content/gdrive', force_remount=True)

root_path = 'gdrive/My Drive/Colab Notebooks/'

"""#Import Data"""

#!kaggle datasets download -d puneet6060/intel-image-classification

"""#Read in Data"""

# set the directory based on the folder where you saved dataset
train_data_dir = root_path+'seg_train/seg_train' 
test_data_dir = root_path+'seg_test/seg_test'
image_generator = ImageDataGenerator(rescale=1/255, validation_split=0.2)    

train_data = image_generator.flow_from_directory(batch_size=64,
                                                 directory=train_data_dir,
                                                 shuffle=True,
                                                 target_size=(64,64), 
                                                 subset="training",
                                                 class_mode='categorical')

val_data = image_generator.flow_from_directory(batch_size=64,
                                                 directory=train_data_dir,
                                                 shuffle=True,
                                                 target_size=(64,64), 
                                                 subset="validation",
                                                 class_mode='categorical')
test_gen = ImageDataGenerator(rescale=1./255)
test_data = test_gen.flow_from_directory(test_data_dir,
                                       target_size=(64,64), batch_size=64, shuffle=False)


print(train_data.classes)
print(val_data.classes)
print(train_data.class_indices)
print(test_data.classes)
class_names = np.unique(train_data.classes)

"""#Baseline Model"""

def create_baseline_model():
  model = Sequential()
  model.add(Conv2D(filters=64, 
                   kernel_size=(3,3), 
                   activation='relu',
                   input_shape=(64,64,3),
                   padding='same'))
  model.add(MaxPooling2D(pool_size= (2,2)))
  model.add(Conv2D(filters=64, 
                   kernel_size=(3,3), 
                   activation='relu',
                   input_shape=(64,64,3),
                   padding='same'))
  model.add(MaxPooling2D(pool_size= (2,2)))
  model.add(Conv2D(filters=64, 
                   kernel_size=(3,3), 
                   activation='relu',
                   input_shape=(64,64,3),
                   padding='same'))
  model.add(MaxPooling2D(pool_size= (2,2)))
  model.add(Flatten())
  model.add(Dense(units=64, activation='relu'))
  model.add(Dense(units=32, activation='relu'))
  model.add(Dense(units=6, activation='softmax'))
  
  return model

baseline_model = create_baseline_model()
baseline_model.summary()

"""### Compile model"""

baseline_model.compile(optimizer='adam', 
                       loss='categorical_crossentropy',
                       metrics=['accuracy'])

"""### Fit model"""

baseline_history = baseline_model.fit(train_data, 
                                      validation_data=val_data,
                                      epochs=20, batch_size=32)

"""### Accuracy plot"""

# accuracy of the model
plt.figure(figsize=(12, 6))
plt.plot(bl_model.history.history["accuracy"])
plt.plot(bl_model.history.history["val_accuracy"])
plt.xlabel("Epochs")
plt.ylabel("Accuracy")
plt.title("ACCURACY OF MODEL")
plt.legend(['training_accuracy', 'validation_accuracy'])
plt.show()

"""### Loss plot"""

# loss of the model
plt.figure(figsize=(12, 6))
plt.plot(bl_model.history.history["loss"])
plt.plot(bl_model.history.history["val_loss"])
plt.xlabel("Epochs")
plt.ylabel("Loss")
plt.title("LOSS OF MODEL")
plt.legend(['training_loss', 'validation_loss'])
plt.show()

test_loss, test_acc = baseline_model.evaluate(test_data)
test_acc

classes = list(test_data.class_indices.keys())

predictions = baseline_model.predict(test_data)
test_pred = np.argmax(predictions, axis=1)

"""#### Confusion matrix"""

print(classification_report(test_data.classes, test_pred, target_names=classes))

cm = confusion_matrix(test_data.classes, test_pred)
cmn = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
fig, ax = plt.subplots(figsize=(6,6))
sns.heatmap(cmn, annot=True, fmt='.2f', xticklabels=classes, yticklabels=classes)
plt.ylabel('Actual')
plt.xlabel('Predicted')
plt.show()

"""#Improved Model

###Hyperparameter tuning 1 (data augmentation + extra layers)
"""

def create_model():
  model = Sequential()
  model.add(Conv2D(filters=64, 
                   kernel_size=(3,3), 
                   activation='relu',
                   input_shape=(64,64,3),
                   padding='same'))
  model.add(MaxPooling2D(pool_size= (2,2)))
  model.add(Conv2D(filters=64, 
                   kernel_size=(3,3), 
                   activation='relu',
                   input_shape=(64,64,3),
                   padding='same'))
  model.add(MaxPooling2D(pool_size= (2,2)))
  model.add(Conv2D(filters=64, 
                   kernel_size=(3,3), 
                   activation='relu',
                   input_shape=(64,64,3),
                   padding='same'))
  model.add(MaxPooling2D(pool_size= (2,2)))
  model.add(Flatten())
  model.add(Dense(units=64, activation='relu'))
  model.add(Dense(units=32, activation='relu'))
  model.add(Dense(units=6, activation='softmax'))
  
  return model

"""###Hyperparameter tuning 2 Randomgridsearch"""



"""###Compile model"""



"""###Fit model"""

xxxx

from keras.applications.vgg16 import VGG16

# load model
vgg_model = VGG16()
# load model without output layer and specify a new input shape for images
vgg_model = VGG16(include_top=False, input_shape=(64, 64, 3))
# summarize the model
vgg_model.summary()

# mark loaded layers as not trainable
for layer in vgg_model.layers:
    layer.trainable = False

from tensorflow.keras import layers
from keras.models import Model

#Add new classifier layers:
#First Flatten Layer
flat1 = layers.Flatten()(vgg_model.layers[-1].output)

#Add Dense layers with Relu
class1 = layers.Dense(1024, activation='relu')(flat1)
class2 = layers.Dense(512, activation='relu')(class1)
class3 = layers.Dense(256, activation='relu')(class2)
class4 = layers.Dense(128, activation='relu')(class3)
class5 = layers.Dense(64, activation='relu')(class4)
class6 = layers.Dense(32, activation='relu')(class5)

#Add Output layer with Softmax
output = layers.Dense(6, activation='softmax')(class6)

#Define the new model
vgg_model = Model(inputs=vgg_model.inputs, outputs=output)
vgg_model.summary()

#Compile model 
vgg_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

#Train Model on trainset #Batchsize?
vgg_model_history = vgg_model.fit(train_data, validation_data = val_data, batchsize = 32, epochs=25, verbose=1)

#Check acc performance
vgg_test_loss, vgg_test_acc = vgg_model.evaluate(test_data)
print(f" VGG test acc:(vgg_test_acc)")
print(f" VGG test loss: (vgg_test_loss)")

#ROC curve with AUC score, performance measures and confusion matrix 
#And compare to baseline model and improved baseline model
#Acc
plt.figure(figsize=(12, 6))
plt.plot(vgg_model_history_history.history["accuracy"])
plt.plot(vgg_model_history.history["val_accuracy"])
plt.xlabel("Epochs")
plt.ylabel("Accuracy")
plt.title("ACCURACY OF VGG MODEL")
plt.legend(['training_accuracy', 'validation_accuracy'])
plt.show()

#Loss
plt.figure(figsize=(12, 6))
plt.plot(vgg_model_history.history["loss"])
plt.plot(vgg_model_history.history["val_loss"])
plt.xlabel("Epochs")
plt.ylabel("Loss")
plt.title("LOSS OF VGG MODEL")
plt.legend(['training_loss', 'validation_loss'])
plt.show()

#Predict classes VGG 
vgg_predictions = vgg_model.predict(test_data)
vgg_test_pred = np.argmax(vgg_predictions, axis=1)

#Print classification report VGG Model
classification_report(test_data.classes, vgg_test_pred, target_names=classes, digits=3)

#Confusion matrix VGG
vgg_cm = confusion_matrix(vgg_test_data.classes, vgg_test_pred)
vgg_cmn = vgg_cm.astype('float') / vgg_cm.sum(axis=1)[:, np.newaxis]
fig, ax = plt.subplots(figsize=(6,6))
sns.heatmap(vgg_cmn, annot=True, fmt='.2f', xticklabels=classes, yticklabels=classes)
plt.title("CONFUSION MATRIX VGG MODEL")
plt.ylabel('Actual')
plt.xlabel('Predicted')
plt.show()

#ROC & AUC VGG Model

#plot the ROC curve

y_test_binarized = label_binarize(test_data.classes, classes=np.unique(test_data.classes))
fpr = {}
tpr = {}
thresh = {}
roc_auc = dict()

# number of unique classes
n_classes = len(np.unique(test_data.classes))

plt.figure(figsize=(10,10))
for i in range(n_classes):
    fpr[i], tpr[i], thresh[i] = roc_curve(y_test_binarized[:,i], vgg_predictions[:,i])
    roc_auc[i] = auc(fpr[i], tpr[i])
    
    plt.plot(fpr[i], tpr[i], linestyle='--',
             label = 'ROC curve of class %s (AUC=%0.2f)'%(list(test_data.class_indices.keys())[i], roc_auc[i]))

# Compute micro-average ROC curve and ROC area
fpr["micro"], tpr["micro"], _ = roc_curve(y_test_binarized.ravel(), vgg_predictions.ravel())
roc_auc["micro"] = auc(fpr["micro"], tpr["micro"])

# Compute macro-averages
# First aggregate all false positive rates
all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))

# Then interpolate all ROC curves at this points
mean_tpr = np.zeros_like(all_fpr)
for i in range(n_classes):
    mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])

# Finally average it and compute AUC
mean_tpr /= n_classes

fpr["macro"] = all_fpr
tpr["macro"] = mean_tpr
roc_auc["macro"] = auc(fpr["macro"], tpr["macro"])

plt.plot([0,1], [0,1], 'b--')
plt.plot(fpr["macro"], tpr["macro"], '-', label='macro-average (AUC=%0.2f)'%(roc_auc["macro"]))
plt.plot(fpr["micro"], tpr["micro"], '-', label='micro-average (AUC=%0.2f)'%(roc_auc["micro"]))
plt.legend(loc='lower right')
plt.xlabel('False Positive Rate (FPR)')
plt.ylabel('True Positive Rate (TPR)')
plt.title('Receiver operating characteristic of multi-class VGG Model')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])